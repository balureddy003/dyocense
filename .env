# General configuration
LLM_PROVIDER=azure
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gpt-4o-mini

# Optional OpenAI configuration (uncomment to use OpenAI)
# OPENAI_API_KEY=
# OPENAI_MODEL=gpt-4o-mini

# Optional Azure OpenAI configuration (requires azure-ai-openai)
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_DEPLOYMENT=2025-01-01-preview
AZURE_OPENAI_TEMPERATURE=0.0
AZURE_OPENAI_MAX_TOKENS=2048
AZURE_OPENAI_EMBED_DEPLOYMENT=text-embedding-3-small

# Orchestrator defaults
DEFAULT_TENANT=demo-tenant
DEFAULT_PROJECT=demo-project
OLLAMA_TIMEOUT=300

# Evidence graph (Neo4j)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=neo4j123
NEO4J_DATABASE=neo4j

# Optimiser configuration
OPTIMISER_BACKEND=ortools  # or 'pyomo'
PYOMO_SOLVER=cbc          # solver name for Pyomo backend

# Forecast configuration
FORECAST_DEFAULT_SEASONAL_PERIOD=12

# Mongo configuration
MONGO_URI=mongodb://dyocense:dyocenseDev123@localhost:27017/?authSource=admin
MONGO_DB_NAME=dyocense

# MinIO / object storage (optional for forecast data ingestion)
MINIO_ENDPOINT=http://localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin

# Knowledge plane configuration
KNOWLEDGE_BACKEND=qdrant  # set to 'qdrant' to use QdrantKnowledgeStore (supports Azure embeddings)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION=dyocense_ops_context

# Iceberg / Nessie metadata (optional)
NESSIE_ENDPOINT=http://localhost:19120/api/v1
# ICEBERG_SNAPSHOT=
