version: "3.9"

# =====================================================================
# Dyocense v4.0 - Production-Ready Infrastructure Stack
# =====================================================================
# Purpose: Complete external services for production deployment
# Architecture: PostgreSQL + Observability Stack (Prometheus/Grafana/Jaeger/Loki)
# Target: Production deployment with monitoring and tracing
# Cost: ~$100-200/month on managed services (all services included)
# =====================================================================

services:
  # ===================================================================
  # DATABASE LAYER
  # ===================================================================
  
  # PostgreSQL with TimescaleDB + pgvector + Apache AGE
  postgres:
    image: timescale/timescaledb-ha:pg16
    container_name: dyocense-postgres
    restart: unless-stopped
    
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-dyocense}
      POSTGRES_USER: ${POSTGRES_USER:-dyocense}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-change_in_production}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=en_US.UTF-8"
      # TimescaleDB configuration
      TIMESCALEDB_TELEMETRY: "off"
      TS_TUNE_MEMORY: ${TS_TUNE_MEMORY:-4GB}
      TS_TUNE_NUM_CPUS: ${TS_TUNE_NUM_CPUS:-2}
    
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./infra/postgres/schema.sql:/docker-entrypoint-initdb.d/01-schema.sql:ro
      - ./infra/postgres/extensions.sql:/docker-entrypoint-initdb.d/02-extensions.sql:ro
      - ./infra/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
    
    ports:
      - "${POSTGRES_PORT:-5433}:5432"
    
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c shared_preload_libraries=timescaledb,pg_stat_statements
      -c max_connections=200
      -c shared_buffers=1GB
      -c effective_cache_size=3GB
      -c maintenance_work_mem=256MB
      -c work_mem=10MB
    
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-dyocense} -d ${POSTGRES_DB:-dyocense}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 1G
    
    networks:
      - backend
      - monitoring

  # ===================================================================
  # CACHING & MESSAGE QUEUE (Optional - for high-scale)
  # ===================================================================
  
  # Redis - LLM response caching, session storage
  redis:
    image: redis:7-alpine
    container_name: dyocense-redis
    restart: unless-stopped
    
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --requirepass ${REDIS_PASSWORD:-change_in_production}
    
    volumes:
      - redis_data:/data
    
    ports:
      - "${REDIS_PORT:-6379}:6379"
    
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
    
    networks:
      - backend
    
    profiles:
      - cache
      - production

  # ===================================================================
  # OBSERVABILITY STACK
  # ===================================================================
  
  # Prometheus - Metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: dyocense-prometheus
    restart: unless-stopped
    
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    
    volumes:
      - ./infra/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./infra/prometheus/alerts:/etc/prometheus/alerts:ro
      - prometheus_data:/prometheus
    
    ports:
      - "${PROMETHEUS_PORT:-9091}:9090"
    
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    
    networks:
      - monitoring
    
    profiles:
      - monitoring
      - production

  # Grafana - Dashboards and visualization
  grafana:
    image: grafana/grafana:latest
    container_name: dyocense-grafana
    restart: unless-stopped
    
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_SERVER_ROOT_URL: ${GRAFANA_ROOT_URL:-http://localhost:3000}
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-piechart-panel
      GF_AUTH_ANONYMOUS_ENABLED: "false"
      GF_ANALYTICS_REPORTING_ENABLED: "false"
      GF_ANALYTICS_CHECK_FOR_UPDATES: "false"
      GF_USERS_ALLOW_SIGN_UP: "false"
    
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infra/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./infra/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    
    ports:
      - "${GRAFANA_PORT:-3001}:3000"
    
    depends_on:
      - prometheus
    
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
    
    networks:
      - monitoring
    
    profiles:
      - monitoring
      - production

  # Loki - Log aggregation
  loki:
    image: grafana/loki:latest
    container_name: dyocense-loki
    restart: unless-stopped
    
    command: -config.file=/etc/loki/loki.yml
    
    volumes:
      - ./infra/loki/loki.yml:/etc/loki/loki.yml:ro
      - loki_data:/loki
    
    ports:
      - "${LOKI_PORT:-3101}:3100"
    
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
    
    networks:
      - monitoring
    
    profiles:
      - monitoring
      - production

  # Promtail - Log shipper to Loki
  promtail:
    image: grafana/promtail:latest
    container_name: dyocense-promtail
    restart: unless-stopped
    
    command: -config.file=/etc/promtail/promtail.yml
    
    volumes:
      - ./infra/promtail/promtail.yml:/etc/promtail/promtail.yml:ro
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    
    depends_on:
      - loki
    
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    
    networks:
      - monitoring
    
    profiles:
      - monitoring
      - production

  # Jaeger - Distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: dyocense-jaeger
    restart: unless-stopped
    
    environment:
      COLLECTOR_ZIPKIN_HOST_PORT: ":9411"
      COLLECTOR_OTLP_ENABLED: "true"
      SPAN_STORAGE_TYPE: badger
      BADGER_EPHEMERAL: "false"
      BADGER_DIRECTORY_VALUE: /badger/data
      BADGER_DIRECTORY_KEY: /badger/key
    
    volumes:
      - jaeger_data:/badger
    
    ports:
      - "${JAEGER_UI_PORT:-16686}:16686"      # Jaeger UI
      - "${JAEGER_COLLECTOR_PORT:-14268}:14268"  # Jaeger collector HTTP
      - "${JAEGER_COLLECTOR_GRPC:-14250}:14250"  # Jaeger collector gRPC
      - "${JAEGER_AGENT_PORT:-6831}:6831/udp"    # Jaeger agent UDP
      - "${JAEGER_OTLP_GRPC:-4317}:4317"         # OTLP gRPC
      - "${JAEGER_OTLP_HTTP:-4318}:4318"         # OTLP HTTP
    
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:14269/"]
      interval: 30s
      timeout: 10s
      retries: 3
    
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    
    networks:
      - monitoring
      - backend
    
    profiles:
      - tracing
      - production

  # ===================================================================
  # POSTGRES EXPORTER FOR PROMETHEUS
  # ===================================================================
  
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: dyocense-postgres-exporter
    restart: unless-stopped
    
    environment:
      DATA_SOURCE_NAME: "postgresql://${POSTGRES_USER:-dyocense}:${POSTGRES_PASSWORD:-change_in_production}@postgres:5432/${POSTGRES_DB:-dyocense}?sslmode=disable"
      PG_EXPORTER_EXTEND_QUERY_PATH: "/etc/postgres_exporter/queries.yaml"
    
    volumes:
      - ./infra/prometheus/postgres_exporter_queries.yaml:/etc/postgres_exporter/queries.yaml:ro
    
    ports:
      - "${PG_EXPORTER_PORT:-9188}:9187"
    
    depends_on:
      postgres:
        condition: service_healthy
    
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    
    networks:
      - monitoring
      - backend
    
    profiles:
      - monitoring
      - production

  # ===================================================================
  # REVERSE PROXY (Production)
  # ===================================================================
  
  nginx:
    image: nginx:alpine
    container_name: dyocense-nginx
    restart: unless-stopped
    
    volumes:
      - ./infra/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./infra/nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    
    ports:
      - "${HTTP_PORT:-80}:80"
      - "${HTTPS_PORT:-443}:443"
    
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 64M
    
    networks:
      - frontend
      - backend
    
    profiles:
      - production

# =====================================================================
# VOLUMES
# =====================================================================
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  loki_data:
    driver: local
  jaeger_data:
    driver: local
  nginx_logs:
    driver: local

# =====================================================================
# NETWORKS
# =====================================================================
networks:
  frontend:
    driver: bridge
  
  backend:
    driver: bridge
  
  monitoring:
    driver: bridge

# =====================================================================
# DEPLOYMENT PROFILES
# =====================================================================
#
# Development (Minimal):
#   docker-compose -f docker-compose.external.yml up -d postgres
#
# Development + Cache:
#   docker-compose -f docker-compose.external.yml --profile cache up -d
#
# Development + Monitoring:
#   docker-compose -f docker-compose.external.yml --profile monitoring up -d
#
# Development + Tracing:
#   docker-compose -f docker-compose.external.yml --profile tracing up -d
#
# Full Production Stack:
#   docker-compose -f docker-compose.external.yml --profile production up -d
#
# =====================================================================
# RESOURCE REQUIREMENTS
# =====================================================================
#
# Minimal (Development):
#   - PostgreSQL only
#   - CPU: 1-2 vCPU
#   - RAM: 1-2 GB
#   - Disk: 10 GB
#
# With Monitoring:
#   - PostgreSQL + Prometheus + Grafana + Loki
#   - CPU: 3-4 vCPU
#   - RAM: 4-6 GB
#   - Disk: 50 GB
#
# Full Production:
#   - All services (PostgreSQL + Redis + Full Observability + Nginx)
#   - CPU: 6-8 vCPU
#   - RAM: 8-10 GB
#   - Disk: 100 GB
#
# =====================================================================
# ENVIRONMENT VARIABLES (.env file)
# =====================================================================
#
# # Database
# POSTGRES_DB=dyocense
# POSTGRES_USER=dyocense
# POSTGRES_PASSWORD=secure_password_here
# POSTGRES_PORT=5432
#
# # Redis (optional)
# REDIS_PASSWORD=secure_redis_password
# REDIS_PORT=6379
#
# # Prometheus
# PROMETHEUS_PORT=9090
#
# # Grafana
# GRAFANA_USER=admin
# GRAFANA_PASSWORD=secure_grafana_password
# GRAFANA_PORT=3000
# GRAFANA_ROOT_URL=https://grafana.yourdomain.com
#
# # Loki
# LOKI_PORT=3100
#
# # Jaeger
# JAEGER_UI_PORT=16686
# JAEGER_COLLECTOR_PORT=14268
# JAEGER_AGENT_PORT=6831
# JAEGER_OTLP_GRPC=4317
# JAEGER_OTLP_HTTP=4318
#
# # Nginx (production)
# HTTP_PORT=80
# HTTPS_PORT=443
#
# # TimescaleDB tuning
# TS_TUNE_MEMORY=4GB
# TS_TUNE_NUM_CPUS=2
#
# =====================================================================
# MONITORING ENDPOINTS
# =====================================================================
#
# Grafana Dashboard:    http://localhost:3000
# Prometheus:           http://localhost:9090
# Jaeger UI:            http://localhost:16686
# PostgreSQL:           postgresql://localhost:5432/dyocense
# Redis:                redis://localhost:6379
#
# =====================================================================
